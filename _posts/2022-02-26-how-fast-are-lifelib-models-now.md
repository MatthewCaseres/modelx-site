---
layout: post
comments: true
title: "How fast are lifelib models now?"
categories: lifelib
---

Almost a year ago,
[this post]({% post_url 2021-01-31-fastlife-got-faster %}) was published.
The post is about testing the speed of models in the [fastlife] library.
Since then, lifelib has been updated, and two new libraries,
[basiclife] and [savings] have succeeded old libraries such as [fastlife] and [simplelife].

[simplelife]: https://lifelib.io/projects/simplelife.html
[fastlife]: https://lifelib.io/projects/fastlife.html
[basiclife]: https://lifelib.io/libraries/basiclife/index.html
[savings]: https://lifelib.io/libraries/savings/index.html


[basiclife] and [savings] includes models that run significantly faster than the [fastlife] models. This post is about the speed-test results of the models included in the [basiclife] and [savings]. The hardware environment
is also updated from the one used for the previous test.
In addition, the version of Python is also updated. 


## Models in basiclife and savings

The [basiclife] and savings libraries includes two types of models,
single processing models and parallel processing models.
Here we measure the speed of the parallel processing models. 
The parallel processing models are reimplementation of the corresponding
single processing models and produce the same results as the single processing models.
The parallel processing models run faster than the single processing models,
because vectorized formulas in the models operate
on [numpy] arrays or [pandas] Series and DataFrames representing all the model points in scope. 
The models to test are:

* `BasicTerm_ME` in [basiclife], a traditional basic term product
* `CashValue_ME` in [savings], a saving product with account value 

[numpy]: https://numpy.org/
[pandas]: https://pandas.pydata.org/


## Test results

Here are some major specs of the machine used for this test and the results.

* CPU: 12th Gen Intel Core i7-12700KF
* OS: Windows 11
* Memory: 64GB

| Model | Python ver. | # Model points | # Steps | # Calcs | Run time (Sec.) |
| ----- | ----------- | -------------- | ------- | ---- | ---- |
| `BasicTerm_ME`  | 3.9.7 | 10K | 277 | 5281 | 1.50 | 
| `BasicTerm_ME`  | 3.10.2 | 10K | 277 | 5281 | 0.88 | 
| `CashValue_ME` | 3.9.7 | 10K |  1141 | 46820 | 13.61 | 
| `CashValue_ME` | 3.10.2 | 10K |  1141 | 46820 | 9.85 | 

## Observations


All the runs are significantly improved from the [last test]({% post_url 2021-01-31-fastlife-got-faster %}) performed with [fastlife].
The most significant factor contributed to the improvement is elimination of 
callbacks passed to `apply` method of `DataFrame`
 and `Series`. All the element wise operations on `DataFrame` and `Series` in the models this time are carried out by methods natively provided by pandas.

As [discussed previously]({% post_url 2021-01-31-fastlife-got-faster %}), the models don't take advantage of multiple cores, although the CPU has 20 logical cores.
So the utilization of the CPU was around 7-10% during any of the runs.
If the cores are utilized fully, the speed should be closed to 20 times the results.

The machine difference has material impact too. As mentioned on lifelib's site, 
Running the `BasicTerm_ME` 3.91 sec while the test above shows the same runs take 1.5 or 0.88 seconds,
although this includes the impact of the difference in Python versions.

It is also worth noting that the models run 40-70% faster with Python 3.10 than with Python 3.9.
There has been an initiative going on to make Python faster, and each Python release is expected gain some performance
improvement, as the figures show. Python 3.11 is expected to be faster than Python 3.10.
The links below detail the initiative supported by Guido van Rossum. 


* [Making CPython faster, LWN.net](https://lwn.net/Articles/857754/)
* [Guido van Rossum’s Ambitious Plans for Improving Python Performance – The New Stack](https://thenewstack.io/guido-van-rossums-ambitious-plans-for-improving-python-performance/)
* [Software at Scale 34 - Faster Python with Guido van Rossum](https://www.softwareatscale.dev/p/software-at-scale-34-faster-python?utm_source=url)
* [Python programming: We want to make the language twice as fast, says its creator, ZDNet](https://www.zdnet.com/article/python-programming-we-want-to-make-the-language-twice-as-fast-says-its-creator/)



## Some notes


* `BasicTerm_ME` does not calculate premium rates internally. It reads the rates
  from an Excel file generated by another model. If premium rates are to
  be calculated in the model, another projection needs to be carried out
  for generating the rates, which would increase the run time materially.

* Also, reserve and capital calculations are not reflected in the model.
  The specs of reserve and capital calculations vary depending on
  regulatory or accounting requirments.
